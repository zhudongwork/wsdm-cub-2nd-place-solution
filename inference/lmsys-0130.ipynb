{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4303e43",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-05T07:35:10.241976Z",
     "iopub.status.busy": "2024-08-05T07:35:10.240978Z",
     "iopub.status.idle": "2024-08-05T07:35:10.247863Z",
     "shell.execute_reply": "2024-08-05T07:35:10.245857Z",
     "shell.execute_reply.started": "2024-08-05T07:35:10.241927Z"
    },
    "papermill": {
     "duration": 0.003846,
     "end_time": "2025-01-30T16:04:23.221853",
     "exception": false,
     "start_time": "2025-01-30T16:04:23.218007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7020fe03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:04:23.229957Z",
     "iopub.status.busy": "2025-01-30T16:04:23.229667Z",
     "iopub.status.idle": "2025-01-30T16:05:10.971230Z",
     "shell.execute_reply": "2025-01-30T16:05:10.970199Z"
    },
    "papermill": {
     "duration": 47.751633,
     "end_time": "2025-01-30T16:05:10.977095",
     "exception": false,
     "start_time": "2025-01-30T16:04:23.225462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.2.0) (3.13.1)\r\n",
      "Installing collected packages: triton\r\n",
      "Successfully installed triton-2.2.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install /kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809edd8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:05:10.985680Z",
     "iopub.status.busy": "2025-01-30T16:05:10.985406Z",
     "iopub.status.idle": "2025-01-30T16:06:00.647170Z",
     "shell.execute_reply": "2025-01-30T16:06:00.646112Z"
    },
    "papermill": {
     "duration": 49.671132,
     "end_time": "2025-01-30T16:06:00.651890",
     "exception": false,
     "start_time": "2025-01-30T16:05:10.980758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl\r\n",
      "Requirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.24042abc8.d20240802) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.24042abc8.d20240802) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (1.13.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (2024.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12->xformers==0.0.24042abc8.d20240802) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12->xformers==0.0.24042abc8.d20240802) (1.3.0)\r\n",
      "Installing collected packages: xformers\r\n",
      "Successfully installed xformers-0.0.24+042abc8.d20240802\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install /kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e03038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:06:00.661315Z",
     "iopub.status.busy": "2025-01-30T16:06:00.660571Z",
     "iopub.status.idle": "2025-01-30T16:06:01.744777Z",
     "shell.execute_reply": "2025-01-30T16:06:01.743717Z"
    },
    "papermill": {
     "duration": 1.091034,
     "end_time": "2025-01-30T16:06:01.746714",
     "exception": false,
     "start_time": "2025-01-30T16:06:00.655680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/wsdm-modules-0102/wsdm-modules-0102 human_pref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6d6b3",
   "metadata": {
    "papermill": {
     "duration": 0.00364,
     "end_time": "2025-01-30T16:06:01.754618",
     "exception": false,
     "start_time": "2025-01-30T16:06:01.750978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685517c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:06:01.763470Z",
     "iopub.status.busy": "2025-01-30T16:06:01.763183Z",
     "iopub.status.idle": "2025-01-30T16:06:01.768946Z",
     "shell.execute_reply": "2025-01-30T16:06:01.768234Z"
    },
    "papermill": {
     "duration": 0.012194,
     "end_time": "2025-01-30T16:06:01.770596",
     "exception": false,
     "start_time": "2025-01-30T16:06:01.758402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prepare_test_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prepare_test_file.py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\")\n",
    "df[\"winner_model_a\"] = 1\n",
    "df[\"winner_model_b\"] = 0\n",
    "df = df.fillna(\"none\")\n",
    "df['prompt'] = df['prompt'].apply(lambda x:x[:6000])\n",
    "df.to_parquet(\"test.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343445ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:06:01.779048Z",
     "iopub.status.busy": "2025-01-30T16:06:01.778819Z",
     "iopub.status.idle": "2025-01-30T16:06:04.697384Z",
     "shell.execute_reply": "2025-01-30T16:06:04.696366Z"
    },
    "papermill": {
     "duration": 2.925033,
     "end_time": "2025-01-30T16:06:04.699399",
     "exception": false,
     "start_time": "2025-01-30T16:06:01.774366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python prepare_test_file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d56563",
   "metadata": {
    "papermill": {
     "duration": 0.003873,
     "end_time": "2025-01-30T16:06:04.707577",
     "exception": false,
     "start_time": "2025-01-30T16:06:04.703704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference: gemma2-9b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3bc9683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:06:04.716600Z",
     "iopub.status.busy": "2025-01-30T16:06:04.716351Z",
     "iopub.status.idle": "2025-01-30T16:06:04.723535Z",
     "shell.execute_reply": "2025-01-30T16:06:04.722760Z"
    },
    "papermill": {
     "duration": 0.013568,
     "end_time": "2025-01-30T16:06:04.724949",
     "exception": false,
     "start_time": "2025-01-30T16:06:04.711381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_m0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_m0.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# from xformers.ops.fmha.attn_bias import BlockDiagonalCausalMask\n",
    "from human_pref.models.modeling_gemma2 import Gemma2ForSequenceClassification\n",
    "from human_pref.data.processors import ProcessorPAB, MIDProcessorPAB\n",
    "from human_pref.data.dataset import LMSYSDataset\n",
    "from human_pref.data.collators import VarlenCollator, ShardedMaxTokensCollator\n",
    "from human_pref.utils import to_device\n",
    "\n",
    "import argparse\n",
    "\n",
    "# 创建 ArgumentParser 对象\n",
    "parser = argparse.ArgumentParser(description='这是一个示例程序。')\n",
    "parser.add_argument('--csv_path', default='test.parquet', help='csv path')\n",
    "parser.add_argument('--save_path', default='prob_m0.npy', help='csv path')\n",
    "args = parser.parse_args()\n",
    "\n",
    "model_name_or_path = \"/kaggle/input/lmsys-pretrain-mid-pseudo-v3\"\n",
    "csv_path = args.csv_path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "processor = MIDProcessorPAB(\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=4096,\n",
    "    support_system_role=False,\n",
    ")\n",
    "dataset = LMSYSDataset(\n",
    "    csv_file=csv_path,\n",
    "    query=None,\n",
    "    processor=processor,\n",
    "    include_swap=False,\n",
    "    is_parquet=True,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=80,\n",
    "    num_workers=4,\n",
    "    collate_fn=ShardedMaxTokensCollator(\n",
    "        max_tokens=8192, base_collator=VarlenCollator()\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model for pipelined inference\n",
    "num_hidden_layers = 42\n",
    "device_map = {\n",
    "    \"model.embed_tokens\": \"cuda:0\",\n",
    "    \"model.norm\": \"cuda:1\",\n",
    "    \"score\": \"cuda:1\",\n",
    "}\n",
    "for i in range(num_hidden_layers // 2):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:0\"\n",
    "for i in range(num_hidden_layers // 2, num_hidden_layers):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:1\"\n",
    "\n",
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# inv_freq clones for each device\n",
    "config = model.config\n",
    "dim = config.head_dim\n",
    "inv_freq = 1.0 / (\n",
    "    config.rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32) / dim)\n",
    ")\n",
    "inv_freq0 = inv_freq.to(\"cuda:0\")\n",
    "inv_freq1 = inv_freq.to(\"cuda:1\")\n",
    "\n",
    "\n",
    "# for name, p in model.named_parameters():\n",
    "#     print(name, p.device)\n",
    "# for name, b in model.model.named_buffers():\n",
    "#     print(name, b.device)\n",
    "\n",
    "# pipeline parallelism with two GPUs\n",
    "is_first = True\n",
    "hidden_states = None\n",
    "outs = []\n",
    "for batch in tqdm(dataloader):\n",
    "    for micro_batch in batch:\n",
    "        input_ids = to_device(micro_batch[\"input_ids\"], \"cuda:0\")\n",
    "        seq_info = dict(\n",
    "            cu_seqlens=micro_batch[\"cu_seqlens\"],\n",
    "            position_ids=micro_batch[\"position_ids\"],\n",
    "            max_seq_len=micro_batch[\"max_seq_len\"],\n",
    "            # attn_bias=BlockDiagonalCausalMask.from_seqlens(micro_batch[\"seq_lens\"]),\n",
    "        )\n",
    "        seq_info = to_device(seq_info, \"cuda:0\")\n",
    "        if is_first:\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                prev_hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "            is_first = False\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, prev_hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            continue\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "            hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            outs.append(logits.cpu())\n",
    "\n",
    "# last micro-batch\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "    outs.append(logits.cpu())\n",
    "\n",
    "pred = torch.cat(outs, dim=0)\n",
    "prob = pred.softmax(-1)\n",
    "print(dataset.evaluate(prob.numpy()))\n",
    "\n",
    "np.save(args.save_path, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb2b7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:06:04.733855Z",
     "iopub.status.busy": "2025-01-30T16:06:04.733371Z",
     "iopub.status.idle": "2025-01-30T16:06:04.736501Z",
     "shell.execute_reply": "2025-01-30T16:06:04.735747Z"
    },
    "papermill": {
     "duration": 0.009238,
     "end_time": "2025-01-30T16:06:04.738126",
     "exception": false,
     "start_time": "2025-01-30T16:06:04.728888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python predict_m0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9430de41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:06:04.748417Z",
     "iopub.status.busy": "2025-01-30T16:06:04.747722Z",
     "iopub.status.idle": "2025-01-30T16:11:34.261137Z",
     "shell.execute_reply": "2025-01-30T16:11:34.260239Z"
    },
    "papermill": {
     "duration": 329.52028,
     "end_time": "2025-01-30T16:11:34.263353",
     "exception": false,
     "start_time": "2025-01-30T16:06:04.743073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [04:55<00:00, 73.84s/it]\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2025-01-30 16:11:13.509549: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-01-30 16:11:13.509756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-01-30 16:11:13.698615: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:18<00:00, 18.72s/it]\r\n",
      "{'log_loss': 1.1673806825666764}\r\n"
     ]
    }
   ],
   "source": [
    "!python predict_m0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7191cc12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:11:34.274824Z",
     "iopub.status.busy": "2025-01-30T16:11:34.274571Z",
     "iopub.status.idle": "2025-01-30T16:11:34.281066Z",
     "shell.execute_reply": "2025-01-30T16:11:34.280100Z"
    },
    "papermill": {
     "duration": 0.014188,
     "end_time": "2025-01-30T16:11:34.282800",
     "exception": false,
     "start_time": "2025-01-30T16:11:34.268612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing make_submission_step1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile make_submission_step1.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "preds = np.load(\"prob_m0.npy\")\n",
    "df = pd.read_parquet(\"test.parquet\")\n",
    "df['winer_a'] = preds[:,0]\n",
    "df['winer_b'] = preds[:,1]\n",
    "df['abs'] = abs(preds[:,0] - preds[:,1])\n",
    "df.to_parquet(\"test.parquet\", index=False)\n",
    "\n",
    "df_swap = df[df['abs'] < 0.8]\n",
    "df_swap[\"response_a\"], df_swap[\"response_b\"] = df_swap[\"response_b\"], df_swap[\"response_a\"]\n",
    "df_swap.to_parquet(\"test_swap.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3924c183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:11:34.293241Z",
     "iopub.status.busy": "2025-01-30T16:11:34.293000Z",
     "iopub.status.idle": "2025-01-30T16:11:35.951339Z",
     "shell.execute_reply": "2025-01-30T16:11:35.950119Z"
    },
    "papermill": {
     "duration": 1.666519,
     "end_time": "2025-01-30T16:11:35.954144",
     "exception": false,
     "start_time": "2025-01-30T16:11:34.287625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python make_submission_step1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c3aac",
   "metadata": {
    "papermill": {
     "duration": 0.004743,
     "end_time": "2025-01-30T16:11:35.964353",
     "exception": false,
     "start_time": "2025-01-30T16:11:35.959610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference: llama3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b23dba4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:11:35.975809Z",
     "iopub.status.busy": "2025-01-30T16:11:35.975492Z",
     "iopub.status.idle": "2025-01-30T16:11:35.983062Z",
     "shell.execute_reply": "2025-01-30T16:11:35.982150Z"
    },
    "papermill": {
     "duration": 0.015698,
     "end_time": "2025-01-30T16:11:35.984766",
     "exception": false,
     "start_time": "2025-01-30T16:11:35.969068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_m3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_m3.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from xformers.ops.fmha.attn_bias import BlockDiagonalCausalMask\n",
    "from human_pref.models.modeling_llama import LlamaForSequenceClassification\n",
    "from human_pref.data.processors import ProcessorPAB, MIDProcessorPAB\n",
    "from human_pref.data.dataset import LMSYSDataset\n",
    "from human_pref.data.collators import VarlenCollator, ShardedMaxTokensCollator\n",
    "from human_pref.utils import to_device\n",
    "\n",
    "\n",
    "model_name_or_path = \"/kaggle/input/llama-lmsys-pretrain-mid-pseudo-4096\"\n",
    "csv_path = \"test_swap.parquet\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.deprecation_warnings[\n",
    "    \"sequence-length-is-longer-than-the-specified-maximum\"\n",
    "] = True\n",
    "processor = MIDProcessorPAB(\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=4096,\n",
    "    support_system_role=True,\n",
    ")\n",
    "dataset = LMSYSDataset(\n",
    "    csv_file=csv_path,\n",
    "    query=None,\n",
    "    processor=processor,\n",
    "    include_swap=False,\n",
    "    is_parquet=True,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=80,\n",
    "    num_workers=4,\n",
    "    collate_fn=ShardedMaxTokensCollator(\n",
    "        max_tokens=8192, base_collator=VarlenCollator()\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model for pipelined inference\n",
    "num_hidden_layers = 32\n",
    "device_map = {\n",
    "    \"model.embed_tokens\": \"cuda:0\",\n",
    "    \"model.norm\": \"cuda:1\",\n",
    "    \"score\": \"cuda:1\",\n",
    "}\n",
    "for i in range(num_hidden_layers // 2):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:0\"\n",
    "for i in range(num_hidden_layers // 2, num_hidden_layers):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:1\"\n",
    "\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# inv_freq clones for each device\n",
    "config = model.config\n",
    "dim = config.hidden_size // config.num_attention_heads\n",
    "inv_freq = 1.0 / (\n",
    "    config.rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32) / dim)\n",
    ")\n",
    "inv_freq0 = inv_freq.to(\"cuda:0\")\n",
    "inv_freq1 = inv_freq.to(\"cuda:1\")\n",
    "\n",
    "\n",
    "# for name, p in model.named_parameters():\n",
    "#     print(name, p.device)\n",
    "# for name, b in model.model.named_buffers():\n",
    "#     print(name, b.device)\n",
    "\n",
    "# pipeline parallelism with two GPUs\n",
    "is_first = True\n",
    "hidden_states = None\n",
    "outs = []\n",
    "for batch in tqdm(dataloader):\n",
    "    for micro_batch in batch:\n",
    "        input_ids = to_device(micro_batch[\"input_ids\"], \"cuda:0\")\n",
    "        seq_info = dict(\n",
    "            cu_seqlens=micro_batch[\"cu_seqlens\"],\n",
    "            position_ids=micro_batch[\"position_ids\"],\n",
    "            max_seq_len=micro_batch[\"max_seq_len\"],\n",
    "            attn_bias=BlockDiagonalCausalMask.from_seqlens(micro_batch[\"seq_lens\"]),\n",
    "        )\n",
    "        seq_info = to_device(seq_info, \"cuda:0\")\n",
    "        if is_first:\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                prev_hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "            is_first = False\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, prev_hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            continue\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "            hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            outs.append(logits.cpu())\n",
    "\n",
    "# last micro-batch\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "    outs.append(logits.cpu())\n",
    "\n",
    "\n",
    "pred = torch.cat(outs, dim=0)\n",
    "prob = pred.softmax(-1)\n",
    "print(dataset.evaluate(prob.numpy()))\n",
    "\n",
    "np.save('prob_m3.npy', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdb16517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:11:35.995466Z",
     "iopub.status.busy": "2025-01-30T16:11:35.995224Z",
     "iopub.status.idle": "2025-01-30T16:15:47.032342Z",
     "shell.execute_reply": "2025-01-30T16:15:47.031226Z"
    },
    "papermill": {
     "duration": 251.044859,
     "end_time": "2025-01-30T16:15:47.034559",
     "exception": false,
     "start_time": "2025-01-30T16:11:35.989700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [03:56<00:00, 59.04s/it]\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2025-01-30 16:15:37.684742: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-01-30 16:15:37.684818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-01-30 16:15:37.686591: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:05<00:00,  5.73s/it]\r\n",
      "{'log_loss': 0.6384592763021282}\r\n"
     ]
    }
   ],
   "source": [
    "!python predict_m3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e11edc1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:15:47.047801Z",
     "iopub.status.busy": "2025-01-30T16:15:47.047189Z",
     "iopub.status.idle": "2025-01-30T16:15:47.053108Z",
     "shell.execute_reply": "2025-01-30T16:15:47.052235Z"
    },
    "papermill": {
     "duration": 0.014437,
     "end_time": "2025-01-30T16:15:47.054685",
     "exception": false,
     "start_time": "2025-01-30T16:15:47.040248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing make_submission_step2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile make_submission_step2.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# preds = np.load(\"prob_m3.npy\")\n",
    "df_swap = pd.read_parquet(\"test_swap.parquet\")\n",
    "preds = np.average(\n",
    "    [\n",
    "        df_swap[['winer_a','winer_b']].values,\n",
    "        np.load(\"prob_m3.npy\")[:, [1, 0]],\n",
    "    ],\n",
    "    axis=0,\n",
    "    weights=[3.2, 1],\n",
    ")\n",
    "\n",
    "df = pd.read_parquet(\"test.parquet\")\n",
    "\n",
    "df['winner'] = (df['winer_a'] >= df['winer_b'])\n",
    "df.loc[df['abs'] < 0.8, 'winner'] = (preds[:,0] > preds[:,1])\n",
    "df['winner'] = df['winner'].map({True: 'model_a', False: 'model_b'})\n",
    "\n",
    "sub = df[['id', 'winner']]\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25f80f30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T16:15:47.066507Z",
     "iopub.status.busy": "2025-01-30T16:15:47.066234Z",
     "iopub.status.idle": "2025-01-30T16:15:49.087562Z",
     "shell.execute_reply": "2025-01-30T16:15:49.086721Z"
    },
    "papermill": {
     "duration": 2.029729,
     "end_time": "2025-01-30T16:15:49.089829",
     "exception": false,
     "start_time": "2025-01-30T16:15:47.060100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id   winner\r\n",
      "0   327228  model_b\r\n",
      "1  1139415  model_b\r\n",
      "2  1235630  model_a\r\n"
     ]
    }
   ],
   "source": [
    "!python make_submission_step2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b09e79",
   "metadata": {
    "papermill": {
     "duration": 0.005679,
     "end_time": "2025-01-30T16:15:49.101627",
     "exception": false,
     "start_time": "2025-01-30T16:15:49.095948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10131489,
     "sourceId": 86946,
     "sourceType": "competition"
    },
    {
     "datasetId": 5493674,
     "sourceId": 9102725,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496847,
     "sourceId": 9107963,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6388480,
     "sourceId": 10318738,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6410480,
     "sourceId": 10352229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6415992,
     "sourceId": 10359932,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6423502,
     "sourceId": 10370346,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6466760,
     "sourceId": 10447454,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6466866,
     "sourceId": 10447628,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6472037,
     "sourceId": 10455219,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6475462,
     "sourceId": 10459845,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 206829,
     "modelInstanceId": 184680,
     "sourceId": 216615,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 689.086939,
   "end_time": "2025-01-30T16:15:49.426615",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-30T16:04:20.339676",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
